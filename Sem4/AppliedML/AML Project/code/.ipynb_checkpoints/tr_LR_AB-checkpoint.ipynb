{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmGlRG6lsgTw"
   },
   "source": [
    "##### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "n_AlSjclkUss"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "np.random.seed(229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingore warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNRKcAk2LEXL"
   },
   "source": [
    "### Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61847,
     "status": "ok",
     "timestamp": 1745892725361,
     "user": {
      "displayName": "Gauranga Kumar Baishya",
      "userId": "09042457344042071897"
     },
     "user_tz": -330
    },
    "id": "3z1XFX0ckgb5",
    "outputId": "185df43b-1d54-4244-9894-0806555d3526"
   },
   "outputs": [],
   "source": [
    "# read/prep data\n",
    "dat = pd.read_csv(\"../data/tokenized_reviews.csv\")\n",
    "dat = dat.dropna()\n",
    "dat[\"quote\"] = dat[\"quote\"].astype(int)\n",
    "dat[\"tokenized_words\"] = dat[\"tokenized_words\"].apply(lambda x: x.strip(\"[']\").replace(\"', '\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "U-B3l2kAkisk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1453600, 13), (256518, 13))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 85% train / 15% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(dat.drop(columns=[\"popular\"]),\n",
    "                                                    dat[\"popular\"],\n",
    "                                                    test_size = 0.15,\n",
    "                                                    random_state = 229)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AlMGOkKJkktj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((430924, 13), (256518, 13))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersample train set\n",
    "majority_size = len(y_train[y_train==0])\n",
    "minority_size = len(y_train[y_train==1])\n",
    "majority_indices = y_train[y_train==0].index\n",
    "rng = np.random.default_rng(seed=229)\n",
    "drop_indices = rng.choice(majority_indices, majority_size-minority_size, replace=False)\n",
    "X_train = X_train.drop(drop_indices)\n",
    "y_train = y_train.drop(drop_indices)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popular\n",
       "0    215462\n",
       "1    215462\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popular\n",
       "0    218275\n",
       "1     38243\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((430924, 1), (256518, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_review = X_train[[\"tokenized_words\"]]\n",
    "X_test_review = X_test[[\"tokenized_words\"]]\n",
    "\n",
    "X_train_review.shape, X_test_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LOGISTIC REGRESSION BOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x11931dd00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x105a2dd00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106345d00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107badd00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x105e11d00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1035c9d00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103ea5d00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1043b1d00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "# BAG OF WORDS\n",
    "print(\"\\n\\nLOGISTIC REGRESSION BOW\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# column transorfmer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('countvectorizer', CountVectorizer(), 'tokenized_words'),  \n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# full pipeline\n",
    "\n",
    "bow_pipe = make_pipeline(\n",
    "    preprocessor,\n",
    "    LogisticRegression(\n",
    "        penalty='l2',\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=229,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "# parameters to try\n",
    "parameters = {\n",
    "    'logisticregression__C': (10, 1, 0.01, 0.001)\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "gs_bow_pipe = GridSearchCV(\n",
    "    bow_pipe, parameters,\n",
    "    cv=ShuffleSplit(n_splits=1, test_size=0.15, random_state=229),\n",
    "    n_jobs=-1)\n",
    "\n",
    "gs_bow_pipe.fit(X_train_review, y_train)\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in: {total_time:.2f} seconds\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_bow_pipe.cv_results_)\n",
    "print(gs_bow_pipe.best_params_)\n",
    "\n",
    "# save the best model with pickle\n",
    "with open(\"./logistic_bow_model_a.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gs_bow_pipe.best_estimator_, f)\n",
    "\n",
    "print(\"\\nBest model saved as 'logistic_bow_model_a.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = gs_bow_pipe.predict(X_test_review)\n",
    "predictions = list(map(round,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Specificity :\", tn/(fp+tn))\n",
    "print(\"ROC-AUC :\", roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raupEfc6ruUV"
   },
   "source": [
    "### Review Meta Data Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_tokens = X_train.drop(columns=[\"tokenized_words\"])\n",
    "X_test_no_tokens = X_test.drop(columns=[\"tokenized_words\"])\n",
    "\n",
    "X_train_no_tokens.shape, X_test_no_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 10863793,
     "status": "ok",
     "timestamp": 1745878626981,
     "user": {
      "displayName": "Gauranga Kumar Baishya",
      "userId": "09042457344042071897"
     },
     "user_tz": -330
    },
    "id": "FUdfW-T-koqQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b3dc918c-c8d1-411e-ff68-cfd96a0d64b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LOGISTIC REGRESSION BOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1170.64856005, 1215.27449656, 1254.74963665,  611.09016752,\n",
      "       1465.03414679, 1446.66143703, 1411.2590313 , 1449.59315228]), 'std_fit_time': array([0., 0., 0., 0., 0., 0., 0., 0.]), 'mean_score_time': array([8.82783151, 6.01767755, 8.00530434, 7.28969765, 6.81266022,\n",
      "       6.39399433, 6.1398077 , 8.37145758]), 'std_score_time': array([0., 0., 0., 0., 0., 0., 0., 0.]), 'param_columntransformer__countvectorizer__max_features': masked_array(data=[10000, 10000, 10000, 10000, 50000, 50000, 50000, 50000],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'param_logisticregression__C': masked_array(data=[10.0, 1.0, 0.01, 0.001, 10.0, 1.0, 0.01, 0.001],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value=1e+20), 'params': [{'columntransformer__countvectorizer__max_features': 10000, 'logisticregression__C': 10}, {'columntransformer__countvectorizer__max_features': 10000, 'logisticregression__C': 1}, {'columntransformer__countvectorizer__max_features': 10000, 'logisticregression__C': 0.01}, {'columntransformer__countvectorizer__max_features': 10000, 'logisticregression__C': 0.001}, {'columntransformer__countvectorizer__max_features': 50000, 'logisticregression__C': 10}, {'columntransformer__countvectorizer__max_features': 50000, 'logisticregression__C': 1}, {'columntransformer__countvectorizer__max_features': 50000, 'logisticregression__C': 0.01}, {'columntransformer__countvectorizer__max_features': 50000, 'logisticregression__C': 0.001}], 'split0_test_score': array([0.69752414, 0.69752414, 0.69743489, 0.6977205 , 0.68360079,\n",
      "       0.68360079, 0.68354724, 0.68515378]), 'mean_test_score': array([0.69752414, 0.69752414, 0.69743489, 0.6977205 , 0.68360079,\n",
      "       0.68360079, 0.68354724, 0.68515378]), 'std_test_score': array([0., 0., 0., 0., 0., 0., 0., 0.]), 'rank_test_score': array([2, 2, 4, 1, 6, 6, 8, 5], dtype=int32)}\n",
      "{'columntransformer__countvectorizer__max_features': 10000, 'logisticregression__C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# BAG OF WORDS\n",
    "print(\"\\n\\nLOGISTIC REGRESSION BOW\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# column transorfmer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('standardscaler', StandardScaler(), numerical_cols)       # Scale numerical columns\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# full pipeline\n",
    "\n",
    "bow_pipe = make_pipeline(\n",
    "    preprocessor,\n",
    "    LogisticRegression(\n",
    "        penalty='l2',\n",
    "        solver='saga',\n",
    "        max_iter=5000,\n",
    "        random_state=229,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "# parameters to try\n",
    "parameters = {\n",
    "    'logisticregression__C': (10, 1, 0.01, 0.001)\n",
    "}\n",
    "\n",
    "\n",
    "# Set up GridSearchCV\n",
    "gs_bow_pipe = GridSearchCV(\n",
    "    bow_pipe, parameters,\n",
    "    cv=ShuffleSplit(n_splits=1, test_size=0.15, random_state=229),\n",
    "    n_jobs=-1)\n",
    "\n",
    "gs_bow_pipe.fit(X_train_no_tokens, y_train)\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in: {total_time:.2f} seconds\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_bow_pipe.cv_results_)\n",
    "print(gs_bow_pipe.best_params_)\n",
    "\n",
    "# save the best model with pickle\n",
    "with open(\"./logistic_bow_model_b.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gs_bow_pipe.best_estimator_, f)\n",
    "\n",
    "print(\"\\nBest model saved as 'logistic_bow_model_b.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = gs_bow_pipe.predict(X_test_no_tokens)\n",
    "predictions = list(map(round,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29284,
     "status": "ok",
     "timestamp": 1745878656082,
     "user": {
      "displayName": "Gauranga Kumar Baishya",
      "userId": "09042457344042071897"
     },
     "user_tz": -330
    },
    "id": "967VNz3bs9Xp",
    "outputId": "dc7093f1-0500-4907-f37b-89247eb639cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85    218275\n",
      "           1       0.33      0.61      0.43     38243\n",
      "\n",
      "    accuracy                           0.76    256518\n",
      "   macro avg       0.63      0.70      0.64    256518\n",
      "weighted avg       0.83      0.76      0.79    256518\n",
      "\n",
      "[[171434  46841]\n",
      " [ 14915  23328]]\n",
      "0.6976988598247426\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print(\"Specificity :\", tn/(fp+tn))\n",
    "print(\"ROC-AUC :\", roc_auc_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RNRKcAk2LEXL"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
